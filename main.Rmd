---
title: "Main"
author: "Aniol, Omar, Marcel Aranich"
date: "2026-01-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# install.packages("tidyr")
# install.packages("mltools")
# install.packages("data.table")

library(dplyr)
library(tidyr)
library(stringr)
library(mltools)
library(data.table)
```

## 2. Análisis de logs de servidor usando R (parte II)

### Obtención y carga de los Datos:

> Queremos programar un script con el que podamos hacer una investigación forense sobre un fichero de logs de un servidor de tipo Apache. Los datos del registro del servidor están en el formato estándar e incluyen miles de registros sobre las distintas peticiones gestionadas por el servidor web.
>
> Nuestro programa ha de ser capaz de obtener las respuestas de forma dinámica a las siguientes preguntas utilizando instrucciones de código en R:

#### 1.

> Descomprimir el fichero comprimido que contiene los registros del servidor, y a partir de los datos extraídos, cargar en data frame los registros con las peticiones servidas.

```{r}
logs <- read.table("epa-http.csv",
                   header = FALSE,
                   sep = " ",
                   quote = "\"",
                   stringsAsFactors = FALSE,
                   fill = TRUE)


```

#### 2.

> Incluid en el documento un apartado con la descripción de los datosanalizados: fuente, tipología, descripción de la información contenida (los diferentes campos) y sus valores.

TODO: explicación

### Limpieza de los Datos

#### 3.

> Aprovechando que los datos a analizar son los mismos de la primera práctica, para esta entrega es imprescindible que los datos estén en formato de “datos elegantes”.
>
> Esto incluye la correcta codificación de cada columna de los datos en el tipo adecuado según su naturaleza (numérico, cadena de caracteres, lógico, timestamp, factor, etc.). Además, para esta entrega se valorará también que los datos estén limpios y sin elementos extraños como por ejemplo espacios o signos de puntuación no necesarios.

```{r}

colnames(logs) <- c("host", "timestamp", "resource", "status", "size")

logs <- tidyr::separate(logs, resource, c("method", "resource", "protocol"), sep = " ")

logs$method <- as.factor(logs$method)

logs$protocol <- as.factor(logs$protocol)

logs$timestamp <- gsub("\\[", "", logs$timestamp)
logs$timestamp <- gsub("]$", "", logs$timestamp)
logs$timestamp <- as.POSIXct(logs$timestamp, format = "%d:%H:%M:%OS")


logs$status <- as.integer(logs$status)
logs$status <- as.factor(logs$status)

suppressWarnings(
logs$size <- as.integer(logs$size)
)





head(logs)


```

### Exploración de Datos

#### 4.

> Identificar el *número único de usuarios* que han interactuado directamente con el servidor de forma segregada según si los usuarios han tenido algún tipo de error en las distintas peticiones ofrecidas por el servidor.
>
> Hacer la distinción (break down) del número de usuarios en función de si estos han tenido algún tipo de error durante las interacciones con el servidor y el tipo de error, es decir, ofrecer el número de usuarios que no han tenido ningún error en una de las peticiones gestionadas por el servidor y el caso contrario, el número de usuarios que sí han experimentado algún error para una petición servida según la tipología del error.
>
> Describir en el documento los distintos tipos de errores existentes en la muestra de datos y el número único de usuarios.

```{r}

df_4 <- logs %>% group_by(status) %>% summarise(comptador = n()) %>% arrange(desc(comptador))
head(df_4)

```

### Análisis de Datos

#### 5.

> Analizar los distintos tipos de peticiones HTTP (GET, POST, PUT, DELETE) gestionadas por el servidor, identificando la frecuencia de cada una de estas. Repetir el análisis, esta vez filtrando previamente aquellas peticiones correspondientes a recursos ofrecidos de tipo imagen.

```{r}
df_5_1 <- logs %>% group_by(method) %>% summarise(comptador = n()) %>% arrange(desc(comptador))
head(df_5_1)
```

```{r}
tipus <- logs %>% mutate(extensio = str_extract(resource, "(?<=\\.)[^\\.]+$"))
extensions_imatge <- c("jpg", "jpeg", "png", "gif", "bmp", "svg", "ico")
imatges <- tipus %>%
  filter(extensio %in% extensions_imatge)

df_5_2 <- imatges %>%
  group_by(method) %>%
  summarise(comptador = n()) %>%
  arrange(desc(comptador))
head(df_5_2)


```
### Visualización de Resultados

#### 6.

> Generar al menos 2 gráficos distintos que permitan visualizar alguna característica relevante de los datos analizados.
>
> Estos deberán representar por lo menos 1 o 2 variables diferentes del data frame. Describid el gráfico e indicad cualquier observación destacable que se pueda apreciar gracias a la representación gráfica.

```{r}

```

#### 7.

> Generar un gráfico que permita visualizar el número de peticiones servidas a lo largo del tiempo.
>
> Pista: Es imprescindible haber codificado correctamente el tipo de cada columna, y en particular, el de la columna usada para representar el momento en que se sirve la respuesta. Con un formato adecuado, será más fácil potencialmente extraer nuevas columnas derivadas de la original que puedan ayudar en la representación de la información (día, hora, etc.)

```{r}

```

## Clústering de datos

#### 8.

> Utilizando un algoritmo de aprendizaje no supervisado, realizad un análisis de clústering con k-means para los datos del servidor.
>
> -   Para este análisis debéis repetir la ejecución del modelado con distintos valores de k (número de clústeres) con al menos 2 valores diferentes de k.
> -   A fin de retener algo de información sobre el recurso servido, generad una columna numérica derivada de esta con el número de caracteres de la URL servida.

Para processar la columna de **resources**, usaremos el tipo de recurso que se está intentando obtener. Por ejemplo para `/icons/circle_logo_small.gif` -\> `gif`. Si no hay ningún tipo, entonces usaremos `None` como un factor para indicar eso. Existen casos dónde el tipo que obtenemos no tiene sentido, pero és un problema que hemos decidido aceptar.

```{r warning=FALSE}

# -   host: discard - no useful data
# -   timestamp: normalización 0-1 (t - min / (max - min))
# -   method: one hot encoding
# -   resource: discard
# -   protocol: discard - all are equal but 1 outlier
# -   status: one hot encoding
# -   size: use (log scale ? + normalize 0 1) + discard NA

df <- tidyr::separate(
  logs, 
  resource, 
  c("resource_1", "type"), 
  sep="(?=\\.[^.]+$)", 
  remove = FALSE, 
  extra = "merge", 
  fill = "right")

df$type[is.na(df$type)] <- "None"
df$type <- as.factor(df$type)

```

Para el siguiente paso, procesaremos **size**. Para empezar, existen algunos valores que són `NA`, por lo que tenemos que gestionarlos. Para eso hay 2 opciones:

-   Descartar las entradas que contengan `NA`.
-   Dar un valor por defecto a los `NA`, cómo 0 o el valor medio del dataset.

Hemos decidido descartar las filas con `NA`. 

Ahora que tenemos un tipo púramente numérico, podemos trabajar con él. Si miramos algunos de los datos podemos ver que los datos abarcan múltiples órdenes de magnitud, por lo que tiene sentido processsarlos en una escala logarítmica, particularmente sabiendo que solamente hay datos no-negativos. 

Optional: Además, aplicaremos la normalización min-max. 


```{r}

df <- df %>% drop_na()

df$size <- log1p(df$size)

if (FALSE) {
  
  size_min <- min(df$size) # 0.0
  size_max <- max(df$size)
  
  df$size <- (df$size - size_min) / (size_max - size_min)
}

# Opcional: multiplicar por constatne para ajustar tamaños
# df$size <- df$size * 2.5


```

Ahora processamos **method** y **status**. Para transformarlos a datos numéricos usaremos one hot encoding. 

```{r}


# one_hot(df, cols = "method")
one_hot_method <- model.matrix(~ method - 1, df)
one_hot_method <- as.data.frame(one_hot_method) 

# one_hot(df, cols = "status")
one_hot_status <- model.matrix(~ status - 1, df)
one_hot_status <- as.data.frame(one_hot_status) 



```


#### 9.

> Representad visualmente en gráficos de tipo scatter plot el resultado de vuestros clústering y interpretad el resultado obtenido.
>
> (describid las características de los distintos grupos) con los 2 valores distintos de k probados en el apartado anterior en función de los valores de las variables y el número de clúster asignado.

```{r}

```
